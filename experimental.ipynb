{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcaa82d6-cd70-4f95-b936-939b56e16be7",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5bd49-0616-4088-bba4-dda9544b1623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from utils.config import cfg\n",
    "from utils.dataset import TrainDataset\n",
    "from utils.mask import tensor_arr_dist_circle_mask, tensor_img_dist_circle_mask, tensor_img_px_circle_mask, get_tensor_img_px_circle_mask_rgb\n",
    "from utils.optical_flow.spynet import spynet_optical_flow \n",
    "from utils.optical_flow.farneback import farneback_optical_flow\n",
    "from utils.visualization import show_imgs, show_farneback_optical_flows, save_spynet_optical_flows\n",
    "from utils.pose import get_circular_poses, tensor_to_cv2\n",
    "\n",
    "# Dataset and Loader\n",
    "cfg.merge_from_file('config/predict_friction_mass_independent-spynet-resnet18-pybullet.yaml')\n",
    "print(cfg)\n",
    "\n",
    "dataset_test = TrainDataset(\n",
    "    [[os.path.join('data/same_vis_same_phys/train/', fp) for fp in os.listdir('data/same_vis_same_phys/train/')][1]],\n",
    "    cfg)\n",
    " \n",
    "loader_train = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=1,  # we have modified data_parallel\n",
    "    shuffle=False,  # we do not use this param\n",
    "    drop_last=True,\n",
    "    num_workers=4,\n",
    "    collate_fn = (lambda x: x),\n",
    "    pin_memory=True)\n",
    "\n",
    "# create loader iterator\n",
    "iterator_train = iter(loader_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db05279f-2ac5-40ec-8304-aa9fbb4b89ab",
   "metadata": {},
   "source": [
    "### Result Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7993356-51d1-4d65-95d6-50dd3fed44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an example\n",
    "output = iterator_train.next()\n",
    "output = output[0]['img_data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e5d3e-adc6-4b27-8b6d-ce68e8b60da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(x, y):\n",
    "    \"\"\"\n",
    "    Compute the Manhattan distance between two vectors x and y using PyTorch.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): A PyTorch tensor of shape (N, D) representing the first vector.\n",
    "        y (torch.Tensor): A PyTorch tensor of shape (N, D) representing the second vector.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A PyTorch tensor of shape (N,) containing the Manhattan distance between each pair of\n",
    "        vectors in x and y.\n",
    "    \"\"\"\n",
    "    return torch.sum(torch.abs(x - y), dim=1)\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "y = torch.tensor([[2, 3, 4], [5, 6, 7], [8, 9, 10]])\n",
    "\n",
    "print(manhattan_distance(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a170372e-5fb2-4835-9b29-729a630ca996",
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_distance(x[:, :2],y[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ef0f4-d75b-4076-9ff5-41033cbf05c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_mse(image1, image2):\n",
    "    \"\"\"\n",
    "    Compute the pixel-wise mean squared error (MSE) between two images with dimensions C,H,W using PyTorch.\n",
    "\n",
    "    Args:\n",
    "        image1 (torch.Tensor): A PyTorch tensor of shape (C, H, W) representing the first image.\n",
    "        image2 (torch.Tensor): A PyTorch tensor of shape (C, H, W) representing the second image.\n",
    "\n",
    "    Returns:\n",
    "        float: The pixel-wise mean squared error (MSE) between image1 and image2.\n",
    "    \"\"\"\n",
    "    return torch.mean(torch.pow(image1 - image2, 2))\n",
    "\n",
    "\n",
    "x = output[0]\n",
    "y = output[2]\n",
    "\n",
    "print(pixel_mse(x, y))  # Output: tensor([ 3,  3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd7a4a-1893-4ed4-b0a5-a31b8647375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_distance(torch.FloatTensor([[37.5818, 18.2550]]), torch.FloatTensor([[33.8364, 22.7585]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb854c52-4526-4e03-8b9a-343674a40f20",
   "metadata": {},
   "source": [
    "### Extract integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93fb7fc-11a8-4ed9-a976-611b7c8e7e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_integers(filename):\n",
    "    split_list = filename.split('.')[0].split('_') \n",
    "    int1 = split_list[1]\n",
    "    int2 = split_list[3]\n",
    "    return int(f'{int1}{int2}')\n",
    "\n",
    "def extract_integer(filename):\n",
    "    return int(filename.split('.')[0].split('_')[1])\n",
    "\n",
    "\n",
    "def check_list(input_list):\n",
    "    for buffer_idx, buffer in enumerate(input_list):\n",
    "        previous_timestep = -1\n",
    "        for timestep_file in buffer:\n",
    "            file_parts = timestep_file.split('_')\n",
    "            current_buffer = int(file_parts[1])\n",
    "            current_timestep = int(file_parts[3].split('.')[0])\n",
    "\n",
    "            if current_buffer != buffer_idx or current_timestep != previous_timestep + 1:\n",
    "                return False\n",
    "\n",
    "            previous_timestep = current_timestep\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "sample_list = [['buffer_0_timestep_0.png', 'buffer_0_timestep_1.png', 'buffer_0_timestep_2.png'],\n",
    "               ['buffer_1_timestep_0.png', 'buffer_1_timestep_1.png', 'buffer_1_timestep_-1.png'],\n",
    "               ['buffer_2_timestep_0.png', 'buffer_2_timestep_1.png', 'buffer_2_timestep_2.png']]\n",
    "\n",
    "result = check_list(sample_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dddaa6d-ce32-414e-bfe6-98f103141926",
   "metadata": {},
   "source": [
    "### Mean color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa966d-3cee-44e9-8158-a876584ab97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an example\n",
    "output = iterator_train.next()\n",
    "output = output[0]['img_data'][0]\n",
    "\n",
    "p0 = get_circular_poses(output[0]).numpy()\n",
    "\n",
    "rgb_values = get_tensor_img_px_circle_mask_rgb(output[0], p0[0,0], p0[0,1], p0[0,2])\n",
    "print(len(rgb_values))\n",
    "mean_rgb = rgb_values.mean(axis=0) \n",
    "print(mean_rgb)\n",
    "plt.imshow([[tuple(mean_rgb.numpy())]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa42ab70-e09e-445a-912f-069e56c57e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_mse(torch.rand((2,256,256)), torch.rand((2,256,256)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195b095b-d15f-4590-8506-52855e176d3b",
   "metadata": {},
   "source": [
    "### Multi-Object Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edea95d-6976-4f9c-ab52-dad427cf26e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an example\n",
    "output = iterator_train.next()\n",
    "output = output[0]['img_data'][0]\n",
    "\n",
    "p0= get_circular_poses(output[0]).numpy()\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "for i in range(len(output)-1):\n",
    "    opt_flow_1 = spynet_optical_flow(output[i], output[i+1])\n",
    "    opt_flow_2 = farneback_optical_flow(output[i], output[i+1])\n",
    "    print(pixel_mse(opt_flow_1, opt_flow_2).detach().numpy())\n",
    "    p1 = []\n",
    "    for keypoint in p0:\n",
    "        x, y = keypoint[0], keypoint[1]\n",
    "        x += opt_flow_2[0,int(y), int(x)].detach().numpy()\n",
    "        y += opt_flow_2[1,int(y), int(x)].detach().numpy()\n",
    "        p1.append([x, y, keypoint[2]])\n",
    "        print(x,y,keypoint[2])\n",
    "        show_imgs([tensor_img_px_circle_mask(output[i+1], x, y, keypoint[2]+10)])\n",
    "    \n",
    "    p0 = p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a49953d-acd9-4bf3-bb35-a8fc5aaa0b0b",
   "metadata": {},
   "source": [
    "## Metres to pixel based masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa4b1b-ccd6-4450-9bf2-5a2e4fdf2ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px_per_m calculation\n",
    "q = 55.0 * np.pi / 180\n",
    "focal_length = 256.0 / np.tan(q/2)\n",
    "px_per_m = focal_length * 1/2\n",
    "m_per_px = 1 / px_per_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a92bd-47e3-4919-bcd9-4759c456710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backtracking 256 px_per_m to q\n",
    "focal_length = 2 * 256\n",
    "q = np.arctan(256.0 / focal_length) * 2 * 180 / np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc10b3b3-a7f6-490a-9248-b269c1f29021",
   "metadata": {},
   "source": [
    "## Testing images and optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d001d0d-89b2-41b8-88cf-157bb707ddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = iterator_train.next()\n",
    "for i in range(len(output[0]['img_data'][0])):\n",
    "    show_imgs([output[0]['img_data'][0,i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb3c1b-f27d-41fb-9d69-e7fec0634b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cx,cy,cr in output[0]['state_label'][0][0][:, [0,1,-2]].detach().numpy():\n",
    "    show_imgs([tensor_img_dist_circle_mask(output[0]['img_data'][0, 0], cx, cy, cr + 0.05)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56433b7-e8cc-49eb-9199-7646cf5e8739",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_flow_masks = []\n",
    "cxs = []\n",
    "cys = []\n",
    "crs = []\n",
    "\n",
    "for i in range(2):\n",
    "    opt_flow = farneback_optical_flow(output[0]['img_data'][0][i], output[0]['img_data'][0][i+1])\n",
    "    opt_flow_masks.append(opt_flow)\n",
    "    \n",
    "    for j in range(3):\n",
    "        cx = output[0]['state_label'][0][i][j, 0]\n",
    "        cy = output[0]['state_label'][0][i][j, 1]\n",
    "        cr = output[0]['state_label'][0][i][j, -2]\n",
    "        \n",
    "        cxs.append(cx)\n",
    "        cys.append(cy)\n",
    "        crs.append(cr)    \n",
    "        opt_flow_masks.append(tensor_arr_dist_circle_mask(opt_flow, cx, cy, cr, 0.1))\n",
    "\n",
    "for i in range(len(opt_flow_masks)):\n",
    "    show_farneback_optical_flows([opt_flow_masks[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552b4c63-8c92-402f-9d97-745e96159112",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_flow_masks = []\n",
    "cxs = []\n",
    "cys = []\n",
    "crs = []\n",
    "\n",
    "for i in range(2):\n",
    "    opt_flow = spynet_optical_flow(output[0]['img_data'][0][i], output[0]['img_data'][0][i+1])\n",
    "    opt_flow_masks.append(opt_flow)\n",
    "    \n",
    "    for j in range(3):\n",
    "        cx = output[0]['state_label'][0][i][j, 0]\n",
    "        cy = output[0]['state_label'][0][i][j, 1]\n",
    "        cr = output[0]['state_label'][0][i][j, -1]\n",
    "        \n",
    "        cxs.append(cx)\n",
    "        cys.append(cy)\n",
    "        crs.append(cr)    \n",
    "        opt_flow_masks.append(tensor_arr_dist_circle_mask(opt_flow, cx, cy, cr, 0.1))\n",
    "\n",
    "#save_spynet_optical_flows(opt_flow_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e617b-344a-411c-8af1-49a80252fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = output[0]['img_data']\n",
    "output_data = output[0]['state_label']\n",
    "\n",
    "BA, BU, C, H, W = input_data.shape\n",
    "_, _, num_balls, num_features = output_data.shape\n",
    "processed_output_data = output_data\n",
    "\n",
    "C_Final = BU * 3 + (BU - 1) * 2\n",
    "input_processed = torch.zeros(BA, num_balls, C_Final, H, W)\n",
    "assert BU == 3\n",
    "for i in range(BA):\n",
    "    for j in range(BU):\n",
    "        img_orig = input_data[i, j, ...]\n",
    "        for k in range(num_balls):\n",
    "            cx, cy, cr = output_data[i, j, k, [0, 1, -2]]\n",
    "            img_masked = tensor_img_dist_circle_mask(img_orig, cx, cy, cr+0.05)\n",
    "            input_processed[i, k, j * 3:(j + 1) * 3, ...] = img_masked\n",
    "            if j != BU-1:\n",
    "                opt_flow = farneback_optical_flow(input_data[i][j], input_data[i][j+1])\n",
    "                opt_flow_masked = tensor_arr_dist_circle_mask(opt_flow, cx, cy, cr, 0.1)\n",
    "                input_processed[i, k, BU*3 + j*2:BU*3 + (j+1)*2, ...] = opt_flow_masked\n",
    "input_processed = torch.flatten(input_processed, end_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d2412-e862-4273-9dbe-ae158f28a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_processed = input_processed.view(-1, num_balls, C_Final, H, W)\n",
    "#for i in range(BA):\n",
    "   #print(f'batch {i}')\n",
    "   #for k in range(num_balls):\n",
    "       #print(f'ball {k}')\n",
    "       #for j in range(BU):\n",
    "           #print(f'buffer {j}')\n",
    "           #masked_img = input_processed[i,k, j * 3:(j + 1) * 3, ...]\n",
    "           #show_imgs([masked_img])\n",
    "           #if j != BU-1:\n",
    "           #    opt_flow_masked = input_processed[i + k, BU*3 + j*2:BU*3 + (j+1)*2]\n",
    "           #    show_farneback_optical_flows([opt_flow_masked])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94215d7-9b24-4752-8fc4-77b666bddfb6",
   "metadata": {},
   "source": [
    "### labelling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654199c5-811c-4815-83a8-0a5e9c6f1a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.zeros(1000, dtype=torch.long)\n",
    "label[:] = 0\n",
    "\n",
    "output = torch.rand(1000,9)\n",
    "\n",
    "pred_log_prob = F.log_softmax(output, dim=1)\n",
    "preds = torch.argmax(output, dim=1)\n",
    "valid = (label >= 0).long()\n",
    "acc_sum = torch.sum(valid * (preds == label).long())\n",
    "valid_sum = torch.sum(valid)\n",
    "acc = acc_sum.float() / (valid_sum.float() + 1e-10)\n",
    "#print(label)\n",
    "#print(preds)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2312db-2881-43a2-aeee-ea44bc7b11ec",
   "metadata": {},
   "source": [
    "### Dataset indexing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a215afcb-72ea-4a43-b93d-1fc6e986d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2idxs(idx, arr):\n",
    "    if all(len(arr[0]) == len(x) for x in arr):\n",
    "        shape = [len(arr), len(arr[0])]\n",
    "        num_dims = len(shape)\n",
    "        offset = 1\n",
    "        idxs = [0] * num_dims\n",
    "        for i in range(num_dims - 1, -1, -1):\n",
    "            idxs[i] = idx // offset % shape[i]\n",
    "            offset *= shape[i]\n",
    "    else:\n",
    "        count = 0\n",
    "        for i in range(len(arr)):\n",
    "            if count + len(arr[i]) > idx:\n",
    "                idxs = [i, idx - count]\n",
    "                break\n",
    "            count += len(arr[i])\n",
    "    return tuple(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc14747-74e6-42ef-a258-f906fef6f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1999\n",
    "A = np.arange(1000).reshape((8,-1))\n",
    "B = np.arange(1000, 2000).reshape((5,-1))\n",
    "C = list(A) + list(B)\n",
    "i,j = idx2idxs(idx, C)\n",
    "print(i,j)\n",
    "print(C[i][j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
