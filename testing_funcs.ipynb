{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcaa82d6-cd70-4f95-b936-939b56e16be7",
   "metadata": {},
   "source": [
    "### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c5bd49-0616-4088-bba4-dda9544b1623",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data.dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9752/896277739.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moptical_flow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspynet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspynet_optical_flow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data.dataset'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.dataset import MultiDataset\n",
    "\n",
    "from optical_flow.spynet import spynet_optical_flow \n",
    "from optical_flow.farneback import farneback_optical_flow\n",
    "\n",
    "# Dataset and Loader\n",
    "dataset_test = MultiDataset(\n",
    "    ['data/same_vis_same_phys/train/sample_0/',\n",
    "     'data/same_vis_same_phys/train/sample_1/',\n",
    "     'data/same_vis_same_phys/train/sample_2/',\n",
    "     'data/same_vis_same_phys/train/sample_3/'],\n",
    "    img_size=(256, 256),\n",
    "    buffer_size=3,\n",
    "    random_order=True\n",
    "    )\n",
    "\n",
    "loader_train = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=4,  # we have modified data_parallel\n",
    "    shuffle=False,  # we do not use this param\n",
    "    drop_last=True,\n",
    "    pin_memory=True)\n",
    "\n",
    "# create loader iterator\n",
    "iterator_train = iter(loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59345f33-6d03-4eb2-83d5-0890f02c6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = iterator_train.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc10b3b3-a7f6-490a-9248-b269c1f29021",
   "metadata": {},
   "source": [
    "## Testing optical flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6bb5b2-a3b6-4efd-a566-e2dd86abd75a",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b920c-6bf1-4226-8aed-cea5e2f75864",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "\n",
    "\n",
    "def show_imgs(imgs):\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def show_farneback_optical_flows(opt_flows):\n",
    "    fig, axs = plt.subplots(ncols=len(opt_flows), squeeze=False)\n",
    "    for i, opt_flow in enumerate(opt_flows):\n",
    "        opt_flow = opt_flow.detach().numpy()\n",
    "        hsv = np.zeros((256,256, 3), dtype=np.float32)\n",
    "        hsv[..., 1] = 255\n",
    "        mag, ang = cv2.cartToPolar(opt_flow[0, ...], opt_flow[1, ...])\n",
    "        hsv[..., 0] = ang*180/np.pi/2\n",
    "        hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        \n",
    "        axs[0, i].imshow(np.asarray(bgr))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def save_spynet_optical_flows(opt_flows):\n",
    "    for i, opt_flow in enumerate(opt_flows):\n",
    "        objOutput = open(f'out_{i}.flo', 'wb')\n",
    "        np.array([ 80, 73, 69, 72 ], np.uint8).tofile(objOutput)\n",
    "        np.array([ opt_flow.shape[2], opt_flow.shape[1] ], np.int32).tofile(objOutput)\n",
    "        np.array(opt_flow.detach().numpy().transpose(1, 2, 0), np.float32).tofile(objOutput)\n",
    "        objOutput.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0abbc66-75c1-4390-936d-b7cd7a750bd3",
   "metadata": {},
   "source": [
    "### Masking "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a49953d-acd9-4bf3-bb35-a8fc5aaa0b0b",
   "metadata": {},
   "source": [
    "### Metres to pixel based masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa4b1b-ccd6-4450-9bf2-5a2e4fdf2ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px_per_m calculation\n",
    "q = 55.0 * np.pi / 180\n",
    "focal_length = 256.0 / np.tan(q/2)\n",
    "px_per_m = focal_length * 1/2\n",
    "m_per_px = 1 / px_per_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a92bd-47e3-4919-bcd9-4759c456710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backtracking 256 px_per_m to q\n",
    "focal_length = 2 * 256\n",
    "q = np.arctan(256.0 / focal_length) * 2 * 180 / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde678f6-f71d-4711-ac5b-d92d139a7e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale2scale(value, oMin=-1.0, oMax=1.0, nMin=-1.0, nMax=1.0):\n",
    "    \"\"\"\n",
    "    Convert linear scale (min/max) to another linear scale (min/max)\n",
    "    value: value to be converted\n",
    "    oMin: old minimum value\n",
    "    oMax: old maximum value\n",
    "    nMin: new minimum value\n",
    "    nMax: new maximum value\n",
    "    return: value mapped from old range to new range\n",
    "    \"\"\"\n",
    "    oSpan = oMax - oMin\n",
    "    nSpan = nMax - nMin\n",
    "    result = ( ( value - oMin) / oSpan) * nSpan + nMin\n",
    "    return result  \n",
    "\n",
    "\n",
    "def bool_circle_mask(arr, xidx, yidx, rad):\n",
    "    c, h, w = arr.shape\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - xidx)**2 + (Y-yidx)**2)\n",
    "    mask = dist_from_center <= rad\n",
    "    mask = np.repeat(mask[np.newaxis, :, :], c, axis=0)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def arr_circle_mask(arr, xidx, yidx, rad, default_val=0):\n",
    "    result = np.ones_like(arr) * default_val\n",
    "    mask = bool_circle_mask(arr, xidx, yidx, rad)\n",
    "    result[mask] = arr[mask]\n",
    "    return result\n",
    "\n",
    "\n",
    "def tensor_arr_dist_circle_mask(arr, cx, cy, cr, extra_pad=0.05):\n",
    "    arr = arr.detach().numpy()\n",
    "    xidx = int(scale2scale(cx, -1.0, 1.0, 0.0, 256.0))\n",
    "    yidx= int(scale2scale(cy, -1.0, 1.0, 256.0, 0.0))\n",
    "    rad = int(scale2scale(cr + extra_pad, 0.0, 1.0, 0.0, 256.0 // 2))\n",
    "    result = arr_circle_mask(arr, xidx, yidx, rad)\n",
    "    result = torch.from_numpy(result.copy())\n",
    "    return result\n",
    "\n",
    "\n",
    "def tensor_img_px_circle_mask(img, px, py, pr):\n",
    "    result = arr_circle_mask(img.detach().numpy(), px, py, pr)\n",
    "    result = torch.from_numpy(result.copy())\n",
    "    return result\n",
    "\n",
    "\n",
    "def tensor_img_dist_circle_mask(img, cx, cy, cr, extra_pad=0.05):\n",
    "    px = int(scale2scale(cx, -1.0, 1.0, 0.0, 256.0))\n",
    "    py = int(scale2scale(cy, -1.0, 1.0, 256.0, 0.0))\n",
    "    pr = int(scale2scale(cr + extra_pad, 0.0, 1.0, 0.0, 256.0 // 2))\n",
    "    return tensor_img_px_circle_mask(img, px, py, pr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d001d0d-89b2-41b8-88cf-157bb707ddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(output['img_data'][0])):\n",
    "    show_imgs([output['img_data'][0, i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb3c1b-f27d-41fb-9d69-e7fec0634b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cx,cy,cr in output['state_label'][0][0][:, [0,1,-1]].detach().numpy():\n",
    "    show_imgs([tensor_img_dist_circle_mask(output['img_data'][0][0], cx, cy, cr + 0.05)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56433b7-e8cc-49eb-9199-7646cf5e8739",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_flow_masks = []\n",
    "cxs = []\n",
    "cys = []\n",
    "crs = []\n",
    "\n",
    "for i in range(2):\n",
    "    opt_flow = farneback_optical_flow(output['img_data'][0][i], output['img_data'][0][i+1])\n",
    "    opt_flow_masks.append(opt_flow)\n",
    "    \n",
    "    for j in range(3):\n",
    "        cx = output['state_label'][0][i][j, 0]\n",
    "        cy = output['state_label'][0][i][j, 1]\n",
    "        cr = output['state_label'][0][i][j, -1]\n",
    "        \n",
    "        cxs.append(cx)\n",
    "        cys.append(cy)\n",
    "        crs.append(cr)    \n",
    "        opt_flow_masks.append(tensor_arr_dist_circle_mask(opt_flow, cx, cy, cr, 0.1))\n",
    "\n",
    "for i in range(len(opt_flow_masks)):\n",
    "    show_farneback_optical_flows([opt_flow_masks[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552b4c63-8c92-402f-9d97-745e96159112",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_flow_masks = []\n",
    "cxs = []\n",
    "cys = []\n",
    "crs = []\n",
    "\n",
    "for i in range(2):\n",
    "    opt_flow = spynet_optical_flow(output['img_data'][0][i], output['img_data'][0][i+1])\n",
    "    opt_flow_masks.append(opt_flow)\n",
    "    \n",
    "    for j in range(3):\n",
    "        cx = output['state_label'][0][i][j, 0]\n",
    "        cy = output['state_label'][0][i][j, 1]\n",
    "        cr = output['state_label'][0][i][j, -1]\n",
    "        \n",
    "        cxs.append(cx)\n",
    "        cys.append(cy)\n",
    "        crs.append(cr)    \n",
    "        opt_flow_masks.append(tensor_arr_dist_circle_mask(opt_flow, cx, cy, cr, 0.1))\n",
    "\n",
    "#save_spynet_optical_flows(opt_flow_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0248ac-31ae-4a20-85cb-cb4c8c3887f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
